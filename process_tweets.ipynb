{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "\n",
    "# Use your own token\n",
    "from keys import api_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-prime",
   "metadata": {},
   "source": [
    "## 1) Authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token,  access_token_secret = api_tokens.access_token\n",
    "consumer_key, consumer_secret = api_tokens.consumer_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-donna",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_by_user(screen_name, num_of_tweets=-1):\n",
    "    \"\"\"\n",
    "    Retrieve a list of all tweets from the given screen names\n",
    "    Input: \n",
    "        screen_name: A single screen name or a list of screen_names\n",
    "        num_of_tweets: Integer value of tweets to retrieve per user, default gets all tweets allowed (last 30 days)\n",
    "    \"\"\"\n",
    "    all_tweets = []\n",
    "\n",
    "    # Cast to a list if a string is given\n",
    "    if isinstance(screen_name, str):\n",
    "        screen_name = [screen_name]\n",
    "\n",
    "    for user in screen_name:\n",
    "        all_tweets.extend([tweet._json for tweet in tweepy.Cursor(api.user_timeline, screen_name=user, tweet_mode='extended').items(num_of_tweets)])\n",
    "\n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbols(tweet):\n",
    "    \"\"\"\n",
    "    Example: {'text': 'NAK', 'indices': [0, 4]}\n",
    "    Get the symbol mentioned in the tweet directly from the full_text entry\n",
    "    Retrieving the symbol using the indices is preferred to ensure the symbol begins with '$'\n",
    "    Return a list of symbols\n",
    "    \"\"\"\n",
    "    out = set()\n",
    "    for entry in tweet['entities']['symbols']:\n",
    "        symbol = tweet['full_text'][entry['indices'][0]:entry['indices'][1]]\n",
    "        if re.match('\\$[aA-zZ]+', symbol):\n",
    "            out.add(symbol.upper())\n",
    "\n",
    "    return sorted(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Get the polarity (sentiment) and subjectivity of a tweet\n",
    "    Polarity is a float with range -1.0 to 1.0 (-1: negative, 1: positive)\n",
    "    Subjectivity is a float with range 0.0 to 1.0 (0: very objective, 1: very subjective)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    out['sentiment_value'], out['subjectivity_value'] = TextBlob(text).sentiment\n",
    "\n",
    "    # These values are interpreted and not necessarily accurate\n",
    "    if out['sentiment_value'] >= 0.1:\n",
    "        out['sentiment'] = 'positive'\n",
    "    elif out['sentiment_value'] <= -0.2:\n",
    "        out['sentiment'] = 'negative'\n",
    "    else:\n",
    "        # Between -0.2 and 0.1\n",
    "        out['sentiment'] = 'neutral'\n",
    "\n",
    "    if out['subjectivity_value'] >= 0.5:\n",
    "        out['subjectivity'] = 'subjective'\n",
    "    else:\n",
    "        out['subjectivity'] = 'objective'\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-herald",
   "metadata": {},
   "source": [
    "## 2) Get tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggested users: AdnansArk, StockDweebs\n",
    "users = input(\"Input the usernames you want to get tweets from, separate users with a ',' : \").replace(' ', '').split(',')\n",
    "print(f\"Retrieving tweets from: {users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_tweets_by_user(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-louis",
   "metadata": {},
   "source": [
    "## 3) Post-proccess tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_mentioned = {}\n",
    "all_ticker_tweets = []\n",
    "for tweet in tweets:\n",
    "    # removes any https links that are not a part of the tweet\n",
    "    # ex) They\\'re pumping the market too! Goldman Sachs https://t.co/RaOoTgTlJj'\n",
    "    start, end = tweet['display_text_range']\n",
    "    content = tweet['full_text'][start:end]\n",
    "    symbols = get_symbols(tweet)\n",
    "    for ticker in symbols:\n",
    "        obj = {\n",
    "            'user': tweet['user']['screen_name'],\n",
    "            'symbol': ticker,\n",
    "            'created': str(tweet['created_at']),\n",
    "            'content': content,\n",
    "            'favourite_count': tweet['favorite_count'],\n",
    "            'tickers_mentioned': symbols,\n",
    "        }\n",
    "\n",
    "        # Get tweet sentiment\n",
    "        obj.update(get_sentiment(content))\n",
    "\n",
    "        all_ticker_tweets.append(obj)\n",
    "        tickers_mentioned.setdefault(ticker.upper(), []).append(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-partition",
   "metadata": {},
   "source": [
    "## 4) Write results to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame(all_ticker_tweets)\n",
    "if not df_tweets.empty:\n",
    "    # Create filename i.e AdnansArk_<date>\n",
    "    file_name = f\"{'_'.join(df_tweets.user.unique())}_{datetime.datetime.today().strftime('%Y_%h_%d_%s')}\"\n",
    "    df_tweets.to_excel(f\"{file_name}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-supply",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
